{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Kafka Consumer for Reddit </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException, KafkaError\n",
    "import sys\n",
    "import getopt\n",
    "import json\n",
    "from pprint import pformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_cb(stats_json_str):\n",
    "    stats_json = json.loads(stats_json_str)\n",
    "    print('\\nKAFKA Stats: {}\\n'.format(pformat(stats_json)))\n",
    "\n",
    "broker = 'clnode225.clemson.cloudlab.us:6667'\n",
    "group = '1'\n",
    "topics = ['test']\n",
    "    \n",
    "# Consumer configuration\n",
    "# See https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\n",
    "conf = {'bootstrap.servers': broker, \\\n",
    "        'group.id': group, \\\n",
    "        'session.timeout.ms': 6000,\\\n",
    "        'default.topic.config': {'auto.offset.reset': 'smallest'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Consumer instance\n",
    "c = Consumer(**conf)\n",
    "\n",
    "def print_assignment(consumer, partitions):\n",
    "    print('Assignment:', partitions)\n",
    "\n",
    "# Subscribe to topics\n",
    "c.subscribe(topics, on_assign=print_assignment)\n",
    "\n",
    "# Read messages from Kafka, print to stdout\n",
    "try:\n",
    "    while True:\n",
    "        msg = c.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            # Error or event\n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                # End of partition event\n",
    "                sys.stderr.write('%% %s [%d] reached end at offset %d\\n' % (msg.topic(), msg.partition(), msg.offset()))\n",
    "            elif msg.error():\n",
    "                # Error\n",
    "                raise KafkaException(msg.error())\n",
    "        else:\n",
    "            # Proper message\n",
    "            # sys.stderr.write('%% %s [%d] at offset %d with key %s:\\n' % (msg.topic(), msg.partition(), msg.offset(), str(msg.key())))\n",
    "            #jsonData = json.loads(json.loads(msg.value()))\n",
    "            jsonData = json.loads(msg.value())\n",
    "            # print (jsonData['text'])\n",
    "            print(msg.value())\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')\n",
    "\n",
    "# Close down consumer to commit final offsets.\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Activity:\n",
    "\n",
    "- Instructor will set up an infinitely running Kafka producer to grab Reddit's latest posts.\n",
    "\n",
    "- Students develop multiple consumers, each performs one of the following tasks:\n",
    "  - Save all incoming data into a file called **raw.json**.\n",
    "  - Monitors and keep tracks of number of submissions coming to various subreddits. Every five minutes, save the top-5 subreddits with the most submissions to an external file. \n",
    "  - Extract the original URL, the subreddit, and the author of each post coming in from the stream. Store this information in a tab-separated file called **posts.txt**. \n",
    "  - After 10-minute, begin examine the original URL of each post in **posts.txt**. Create a new file called **posts_stat.txt** with the following information: the original URL, the subreddit, the author of each post, number of new comments, number of upvotes/downvotes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
